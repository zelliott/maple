
Prediction of transfusion is presumed to reduce wastage rates in pre-operative autologus blood donation (PABD) and unnecessary providing and cross-matching in allogeneic transfusion. The clinical utility of published algorithms in predicting transfusions was analysed.

In a cohort of 195 patients undergoing total hip arthroplasty, after PABD, expected transfusion needs were predicted with two published algorithms (A and B). The algorithms were then compared to actual transfusions. Assumptions and formulae of these algorithms were varied in an attempt to improve their prognostic utility.

The optimal variation of A resulted in allogeneic transfusions (PABD setting) or uncross-matched transfusions (allogeneic setting) of 27.3%, and a wastage rate of autologous units or unnecessary cross-matching of 73.8%, compared to 33.3% and 76.6%, respectively, for the original algorithm. The original version of algorithm B resulted in (allogeneic) transfusions of 78.8%, and a wastage rate or unnecessary cross-matching of 46.2%. The former could be improved by a variation of the algorithm to 69.7%. Comparing the optimal variations of both algorithms, the more elaborate algorithm A reduced overall transfusion risk significantly better (P =0.001). The two algorithms were not statistically different in reducing resource consumption (P =0.09).

Although the prognostic utility of algorithm A was significantly better for reducing overall transfusion risk, both algorithms were unable to meaningfully identify patients who would benefit from PABD or cross-matching. The algorithms could not increase the percentage of PABD patients transfused, or the percentage of cross-matched patients transfused in the allogeneic setting. Furthermore, they could neither reduce transfusion risk nor resource consumption.

