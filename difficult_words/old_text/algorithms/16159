
We present a practical system for controlling the prehension of a transradial prosthesis. The system is mounted on the artificial hand and comprises simple hardware and software that are convenient for real-time implementation. The hardware consists of a standard web camera and an ultrasound distance sensor. The control algorithm mimics biological mechanisms for the control of grasping and uses the measured distance to the target object and the method of computer vision to estimate the object's size and orientation. Based on these estimates, the algorithm outputs the following commands for the control of prehension: (i) the type of grasp and the aperture size appropriate for the target object; and (ii) the angle through which the wrist should be rotated (pronation/supination) in order to properly position the hand for the grasp. We have tested the system's performance with different targets (planar geometric shapes, real-life objects) under static conditions (i.e., when the system is stationary) and dynamic conditions (i.e., when the system moves toward the target). The size estimation was more accurate in the static experiments (error < 36%). Importantly, the system showed to be very robust with respect to the estimation errors, and the correct control commands were generated in most of the tested cases. The presented system is only one component of the hand controller, related strictly to the prehension phase of grasping. The final solution is envisioned as a combination of the presented system, inertial sensors (hand orientation), and a myoelectric control (triggering).

