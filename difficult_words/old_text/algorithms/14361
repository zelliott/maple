
We propose two information theoretic similarity measures that allow to incorporate tissue class information in non-rigid image registration. The first measure assumes that tissue class probabilities have been assigned to each of the images to be registered by prior segmentation of both of them. One image is then non-rigidly deformed to match the other such that the fuzzy overlap of corresponding voxel object labels becomes similar to the ideal case whereby the tissue probability maps of both images are identical. Image similarity is assessed during registration by the divergence between the ideal and actual joint class probability distributions of both images. A second registration measure is proposed that applies in case a segmentation is available for only one of the images, for instance an atlas image that is to be matched to a study image to guide the segmentation thereof. Intensities in one image are matched to the fuzzy class labels in the other image by minimizing the conditional entropy of the intensities in the first image given the class labels in the second image. We derive analytic expressions for the gradient of each measure with respect to individual voxel displacements to derive a force field that drives the registration process, which is regularized by a viscous fluid model. The performance of the class-based measures is evaluated in the context of non-rigid inter-subject registration and atlas-based segmentation of MR brain images and compared with maximization of mutual information using only intensity information. Our results demonstrate that incorporation of class information in the registration measure significantly improves the overlap between corresponding tissue classes after non-rigid matching. The methods proposed here open new perspectives for integrating segmentation and registration in a single process, whereby the output of one is used to guide the other.

