
Delineation of the prostate from transrectal ultrasound images is a necessary step in several computer-assisted clinical interventions, such as low dose rate brachytherapy. Current approaches to user segmentation require user intervention and therefore it is subject to user errors. It is desirable to have a fully automatic segmentation for improved segmentation consistency and speed. In this paper, we propose a multi-atlas fusion framework to automatically segment prostate transrectal ultrasound images. The framework initially registers a dataset of a priori segmented ultrasound images to a target image. Subsequently, it uses the pairwise similarity of registered prostate shapes, which is independent of the image-similarity metric optimized during the registration process, to prune the dataset prior to the fusion and consensus segmentation step. A leave-one-out cross-validation of the proposed framework on a dataset of 50 transrectal ultrasound volumes obtained from patients undergoing brachytherapy treatment shows that the proposed is clinically robust, accurate and reproducible.

