
In this paper, the optimizations of three fundamental components of image understanding: segmentation/annotation, 3D sensing (stereo) and 3D fitting, are posed and integrated within a Bayesian framework. This approach benefits from recent advances in statistical learning which have resulted in greatly improved flexibility and robustness. The first two components produce annotation (region labeling) and depth maps for the input images, while the third module integrates and resolves the inconsistencies between region labels and depth maps to fit most likely 3D models. To illustrate the application of these ideas, we have focused on the difficult problem of fitting individual tree models to tree stands which is a major challenge for vision-based forestry inventory systems.

