
This paper presents the statistical technique known as the bootstrap to the general audience of psychophysiologists. The bootstrap, introduced by Efron (1979), allows data analysts to study the distribution of sample statistics that might otherwise be too complicated to consider. The technique, which requires simple calculations, involves drawing repeated samples (with replacement) from the empirical--or the actual--data distribution and then building a distribution for a statistic by calculating a value of the statistic for each sample. The bootstrap can be used to obtain confidence intervals, standard errors, and even higher moments for the statistic. It is similar to the well-known jackknife of Quenouille and Tukey. After discussing the history and theory of both the bootstrap and the jackknife, we illustrate the use of the bootstrap in the statistical analysis of correlation coefficients and the general linear model.

