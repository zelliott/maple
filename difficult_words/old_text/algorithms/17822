
The advent of multimodality imaging scanners combining PET and CT has led to a new paradigm in image display and presentation that raises new challenges in workstation interpretation software, image navigation, and communication. The essence of multimodality imaging is the ability to overlay imaging information from different modalities in a visually compelling fashion. This is accomplished by combining functional and anatomic data into multidimensional views using color-encoding techniques that provide visual clues on the spatial distribution of image data.

Combined PET/CT scanners provide spatially registered images from the two modalities acquired simultaneously in a single imaging session. Special reconstruction software and image display programs are required to rescale the native images from different spatial resolution into orthogonal or oblique reformatted planes in which data from PET images are color coded and superimposed on corresponding anatomic CT images. The color overlay technique allows the user to visually identify areas of high tracer activity and determine the underlying anatomic structure. Because of the multidimensional nature of the data, visualization requires interactive multidimensional navigation techniques that allow the viewer to move the visualization planes through three spatial directions and two additional dimensions. The fourth dimension is the continuum blend from PET to CT fusion, and the fifth is the dynamic range of the CT images that can be adjusted to display different tissue characteristics, such as bones, soft tissue, and lungs. Software tools currently available are often relatively complex, requiring the user to perform cumbersome maneuvers and time-consuming image manipulation to navigate through all dimensions and obtain adequate image settings and plane positioning for diagnostic interpretation of the image data. Moreover, the ability to convey these images to referring physicians is usually limited because of the lack of adequate viewing software. Distribution of results is usually performed instead through static "snapshots" of the fused images generated by the interpreting radiologist. The ability of the referring physician to navigate through the set of multimodality image data is thus limited.

The wider adoption of multimodality PET/CT imaging techniques in routine clinical use will depend heavily on the development of more adequate image display and navigation tools that allow interpreting physicians to navigate easily and efficiently through multiple dimensions of data. Distribution of results to referring physicians and care providers also requires new tools for interactively reviewing the multimodality data, and current static images obtained from fused image data remain inadequate for proper visualization of the true content of images.

