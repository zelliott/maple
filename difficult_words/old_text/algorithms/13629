
Behavioral studies and single cell recordings in monkey inferotemporal cortex have documented greater sensitivity to differences in viewpoint invariant or nonaccidental properties (e.g., straight vs. curved), than metric properties (e.g., degree of curvature) of simple shapes. Are we similarly more sensitive to nonaccidental (NAP) than metric (MP) differences of the relations between objects? We addressed this question with sets of scene triplets that could, from a reference or "Base" scene (e.g., a brick slightly separated from a cylinder), undergo a NAP relational change (e.g., the brick attached to the cylinder) or an MP relational change (e.g., the brick further separated from the cylinder). Critically, both relational variations were matched in physical dissimilarity using pixel energy and the Gabor-jet system, a model of V1 similarity. In an adaptive staircase match-to-sample paradigm, subjects required more than double the presentation durations for detecting differences in MP than NAP relations to achieve equivalent levels of accuracy. In two fMRI experiments, NAP changes consistently produced greater responses in the lateral occipital cortex (LO), but not in earlier retinotopic stages, compared to MP changes, implicating LO as the potential neural locus for where the greater detectability of the differences of NAPs than MPs is made explicit. HMAX, a model of cell tuning in higher-level ventral visual areas, did not consistently reflect the marked NAP advantage witnessed in behavioral performance and in LO responses.

