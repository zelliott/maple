
In order to learn grammar from a finite amount of evidence, children must begin with in-built expectations of what is grammatical. They clearly are not born, however, with fully developed grammars. Thus early language development involves refinement of the grammar hypothesis until a target grammar is learnt. Here we address the question of how much evidence is required for this refinement process, by considering two standard learning algorithms and a third algorithm which is presumably as efficient as a child for some value of its memory capacity. We reformulate this algorithm in the context of Chomsky's 'principles and parameters' and show that it is possible to bound the amount of evidence required to almost certainly speak almost grammatically.

