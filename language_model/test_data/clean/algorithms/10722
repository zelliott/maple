
We try a new approach with near-IR time-resolved spectroscopy, to separate optical signals originated in the upper layer from those in the lower layer and to selectively determine the absorption coefficient (mu(a)) of each layer in a two-layered turbid medium. The difference curve in the temporal profiles of light attenuation between a target and a reference medium is divided into segments along the time axis, and a slope of each segment is calculated to determine the depth-dependent mu(a). The depth-dependent mu(a) values are estimated under various conditions in which mu(a) and the reduced scattering coefficient (mu(s)') of each layer are changed with a Monte Carlo simulation and in phantom experiments. Temporal variation of them represents the difference in mu(a) between two layers when mu(s)' of a reference is the same as that of the upper layer of the target. The discrepancies between calculated mu(a) and the real mu(a) depend on the ratio of the real mu(a) of the upper layer to that of the lower layer, and our approach enables us to estimate the ratio of mu(a) between the two layers. These results suggest the potential that mu(a) of the lower layer can be determined by our procedure.

