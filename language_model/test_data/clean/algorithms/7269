
We present a reconstruction-based learning technique to localize the optic cup in fundus images for glaucoma screening. In contrast to previous approaches which rely on low-level visual cues, our method instead considers the input image as a whole and infers its optic cup parameters from a codebook of manually labeled reference images based on their similarity to the input and their contribution towards reconstructing the input image. We show that this approach can be formulated as a closed-form solution without any search, which leads to highly efficient and 100% repeatable computation. Our tests on the ORIGA and SCES datasets show that the performance of this method compares favorably to those of previous techniques while operating at faster speeds. This suggests much promise for this approach to be used in practice for screening.

