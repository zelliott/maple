
In this paper we present an approach to localize endoscopic instruments with respect to the camera position, purely based on video image processing. No localizers are required. The only requirement is a coloured strip at the distal part of the instrument shaft, to facilitate image segmentation. The method exploits perspective image analysis applied to the cylindrical shape of the instrument shaft, allowing to measure five degrees of freedom of the instrument position and orientation. We describe the method theoretically and experimentally derive calibration curves for tuning the parameters of the algorithm. Results show that the method can be used for applications where accuracy is not critical, e.g. workspace analysis, gesture analysis, augmented-reality guidance, telementoring, etc. If this method is used in combination with a robotic camera holder, full localization with respect to the operating room can be achieved.

