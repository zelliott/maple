
Prostate gland segmentation is a critical step in prostate radiotherapy planning, where dose plans are typically formulated on CT. Pretreatment MRI is now beginning to be acquired at several medical centers. Delineation of the prostate on MRI is acknowledged as being significantly simpler to perform, compared to delineation on CT. In this work, the authors present a novel framework for building a linked statistical shape model (LSSM), a statistical shape model (SSM) that links the shape variation of a structure of interest (SOI) across multiple imaging modalities. This framework is particularly relevant in scenarios where accurate boundary delineations of the SOI on one of the modalities may not be readily available, or difficult to obtain, for training a SSM. In this work the authors apply the LSSM in the context of multimodal prostate segmentation for radiotherapy planning, where the prostate is concurrently segmented on MRI and CT.

The framework comprises a number of logically connected steps. The first step utilizes multimodal registration of MRI and CT to map 2D boundary delineations of the prostate from MRI onto corresponding CT images, for a set of training studies. Hence, the scheme obviates the need for expert delineations of the gland on CT for explicitly constructing a SSM for prostate segmentation on CT. The delineations of the prostate gland on MRI and CT allows for 3D reconstruction of the prostate shape which facilitates the building of the LSSM. In order to perform concurrent prostate MRI and CT segmentation using the LSSM, the authors employ a region-based level set approach where the authors deform the evolving prostate boundary to simultaneously fit to MRI and CT images in which voxels are classified to be either part of the prostate or outside the prostate. The classification is facilitated by using a combination of MRI-CT probabilistic spatial atlases and a random forest classifier, driven by gradient and Haar features.

The authors acquire a total of 20 MRI-CT patient studies and use the leave-one-out strategy to train and evaluate four different LSSMs. First, a fusion-based LSSM (fLSSM) is built using expert ground truth delineations of the prostate on MRI alone, where the ground truth for the gland on CT is obtained via coregistration of the corresponding MRI and CT slices. The authors compare the fLSSM against another LSSM (xLSSM), where expert delineations of the gland on both MRI and CT are employed in the model building; xLSSM representing the idealized LSSM. The authors also compare the fLSSM against an exclusive CT-based SSM (ctSSM), built from expert delineations of the gland on CT alone. In addition, two LSSMs trained using trainee delineations (tLSSM) on CT are compared with the fLSSM. The results indicate that the xLSSM, tLSSMs, and the fLSSM perform equivalently, all of them out-performing the ctSSM.

The fLSSM provides an accurate alternative to SSMs that require careful expert delineations of the SOI that may be difficult or laborious to obtain. Additionally, the fLSSM has the added benefit of providing concurrent segmentations of the SOI on multiple imaging modalities.

