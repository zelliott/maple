
Standard gradient coils are designed by minimizing the inductance or resistance for an acceptable level of gradient field nonlinearity. Recently, a new method was proposed to minimize the maximum value of the current density in a coil additionally. The stated aim of that method was to increase the minimum wire spacing and to reduce the peak temperature in a coil for fixed efficiency. These claims are tested in this study with experimental measurements of magnetic field and temperature as well as simulations of the performance of many coils. Experimental results show a 90% increase in minimum wire spacing and 40% reduction in peak temperature for equal coil efficiency and field linearity. Simulations of many more coils indicate increase in minimum wire spacing of between 50 and 340% for the coils studied here. This method is shown to be able to increase coil efficiency when constrained by minimum wire spacing rather than switching times or total power dissipation. This increase in efficiency could be used to increase gradient strength, duty cycle, or buildability.

