
Brain-computer interfaces (BCIs) provide alternative methods for communicating and acting on the world, since messages or commands are conveyed from the brain to an external device without using the normal output pathways of peripheral nerves and muscles. Alzheimer's disease (AD) patients in the most advanced stages, who have lost the ability to communicate verbally, could benefit from a BCI that may allow them to convey basic thoughts (e.g., "yes" and "no") and emotions. There is currently no report of such research, mostly because the cognitive deficits in AD patients pose serious limitations to the use of traditional BCIs, which are normally based on instrumental learning and require users to self-regulate their brain activation. Recent studies suggest that not only self-regulated brain signals, but also involuntary signals, for instance related to emotional states, may provide useful information about the user, opening up the path for so-called "affective BCIs". These interfaces do not necessarily require users to actively perform a cognitive task, and may therefore be used with patients who are cognitively challenged. In the present hypothesis paper, we propose a paradigm shift from instrumental learning to classical conditioning, with the aim of discriminating "yes" and "no" thoughts after associating them to positive and negative emotional stimuli respectively. This would represent a first step in the development of a BCI that could be used by AD patients, lending a new direction not only for communication, but also for rehabilitation and diagnosis.

