
Previous studies have demonstrated that the perceived direction of motion of a visual stimulus can be decoded from the pattern of functional magnetic resonance imaging (fMRI) responses in occipital cortex using multivariate analysis methods (Kamitani and Tong, 2006). One possible mechanism for this is a difference in the sampling of direction selective cortical columns between voxels, implying that information at a level smaller than the voxel size might be accessible with fMRI. Alternatively, multivariate analysis methods might be driven by the organization of neurons into clusters or even orderly maps at a much larger scale. To assess the possible sources of the direction selectivity observed in fMRI data, we tested how classification accuracy varied across different visual areas and subsets of voxels for classification of motion-direction. To enable high spatial resolution functional MRI measurements (1.5mm isotropic voxels), data were collected at 7T. To test whether information about the direction of motion is represented at the scale of retinotopic maps, we looked at classification performance after combining data across different voxels within visual areas (V1-3 and MT+/V5) before training the multivariate classifier. A recent study has shown that orientation biases in V1 are both necessary and sufficient to explain classification of stimulus orientation (Freeman et al., 2011). Here, we combined voxels with similar visual field preference as determined in separate retinotopy measurements and observed that classification accuracy was preserved when averaging in this 'retinotopically restricted' way, compared to random averaging of voxels. This insensitivity to averaging of voxels (with similar visual angle preference) across substantial distances in cortical space suggests that there are large-scale biases at the level of retinotopic maps underlying our ability to classify direction of motion.

