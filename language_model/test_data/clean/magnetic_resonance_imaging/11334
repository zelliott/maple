
A quantitative analysis was undertaken to calibrate the perfusion quantification technique based on tracking the first pass of a bolus of a blood pool contrast agent. A complete simulation of the bolus passage, of the associated changes in the T2 and T2* signals, and of the data processing was performed using the tracer dilution theory, an analytical theory of the MR signal from living tissues and numerical simulations. The noise was excluded in the simulation in order to analyze the ultimate accuracy of the method. It is demonstrated that the relationship between the contrast agent concentration and the associated changes in the transverse relaxation rate shows essentially different forms in studied tissue and in the reference artery. This effect results in systematic deviations of the measured blood flow, blood volume, and the residue function obtained with conventional processing from their true values. The error depends on the microvascular composition, the properties of the contrast agent, and the weights of the various compartments in the total signal. The results show that dynamic susceptibility contrast MRI can reach the goal of absolute perfusion quantification only with additional input from measurements of the microvascular architecture. Alternatively, the method can be used to provide such information if the perfusion is quantified by another modality.

