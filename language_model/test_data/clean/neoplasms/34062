
To examine the prospective association of serum iron, copper, and zinc with cancer mortality.

The study sample included 3000 men and 3244 women free from cancer at baseline who participated in the Second National Health and Nutrition Examination Survey. Vital status at follow-up was identified by the Social Security Administration's death file and the National Death Index. Iron, transferrin saturation (TS), copper, and zinc were categorized into 4 levels using the 10th, 50th, and 90th percentiles for cutoffs. Relative risks (RRs) were derived from the proportional hazard models after adjustment for a number of potential confounders.

Three hundred seven cancer deaths (ICD-9 140-195, 199-208) were identified during 83,664.4 person-years of follow-up. Cancer mortality per 1000 person-years was 3.7 (4.7 for men and 2.8 for women). For men and women combined, the adjusted RRs (95% confidence intervals, CI) for the four levels were 0.96 (0.57-1.61), 1.00 (reference), 1.12 (0.80-1.58), 1.86 (1.07-3.22) for iron; 0.97 (0.56-1.70), 1.00 (reference), 1.36 (0.99-1.87), 1.82 (1.10-3.02) for TS; 0.76 (0.44-1.31), 1.00 (reference), 1.10 (0.77-1.58), 1.89 (1.07-3.32) for copper; and 0.75 (0.50-1.13), 1.00 (reference), 0.64 (0.47-0.88), 0.84 (0.53-1.33) for zinc. When the exposures were analyzed as continuous variables, the adjusted RRs (CI) were 1.66 (1.03-2.68) for 100 microg/dl iron increase, 1.17 (1.01-1.36) for 10% TS increase, 1.98 (1.12-3.50) for 100 microg/dl copper increase, and 0.57 (0.16-1.96) for 100 microg/dl zinc increase. Sex differences in the adjusted RRs for iron, TS, and copper were suggestive.

People with higher serum iron, TS, or copper concentrations had an increased risk of dying from cancer.

