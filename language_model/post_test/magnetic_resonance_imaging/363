
In an everyday social interaction we automatically integrate zzso facial movements and zzso be they linguistic or zzso This requires audiovisual integration of a continual barrage of sensory zzso phenomenon previously well-studied with human audiovisual speech, but not with zzso zzso Using both zzso and zzso we assessed neural activity to viewing and listening to an animated female face producing zzso human zzso zzso zzso zzso under zzso zzso zzso zzso and audiovisual zzso stimulus conditions, alternating with zzso zzso zzso effects occurred in regions dominant for sensory processing, which showed zzso zzso greater than the dominant zzso zzso Right zzso zzso and zzso regions showed an zzso maximum in which zzso zzso was greater than either zzso alone, but not greater than the sum of the zzso zzso Other frontal and zzso regions showed zzso in which zzso zzso was the same as one or both zzso zzso zzso data showed an early zzso effect zzso zzso zzso + zzso no zzso zzso zzso effects for auditory zzso and zzso zzso and late zzso maximum and zzso zzso Based on convergence between zzso and zzso data, we propose a mechanism where a zzso stimulus may be signaled or facilitated as early as 60 zzso and facilitated in zzso regions by increasing processing speed (at zzso and efficiency zzso zzso in auditory and zzso cortical zzso and zzso Finally, zzso processes are also altered, but in a more complex zzso 

