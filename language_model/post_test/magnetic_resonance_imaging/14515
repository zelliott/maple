
We aimed at predicting the zzso evolution of brain activity in zzso music listening conditions using a combination of zzso and acoustic feature zzso Participants were scanned using functional zzso zzso Imaging zzso while listening to two musical zzso including pieces from various genres with and without zzso zzso models were built to predict zzso brain zzso which were then tested in a zzso setting in order to evaluate the zzso of the hence created models across zzso To further assess the zzso of the models we extended the zzso procedure by including another zzso which comprised continuous zzso responses of musically trained participants to an Argentinean zzso Individual models for the two musical zzso revealed that zzso in several areas in the brain belonging to the zzso zzso and motor regions could be zzso zzso zzso in the zzso zzso region and the anterior zzso cortex, relevant for self-referential appraisal and aesthetic judgments, could be predicted zzso zzso across musical stimuli and participant pools helped identify a region of the right superior zzso zzso encompassing the zzso zzso and the zzso zzso as the core structure that processed complex acoustic features of musical pieces from various genres, with or without zzso Models based on purely instrumental music were able to predict zzso in the bilateral auditory zzso zzso zzso and left zzso primary and supplementary motor zzso The presence of lyrics on the other hand weakened the prediction of zzso in the left superior zzso zzso Our results suggest spontaneous zzso processing during zzso listening to music and provide supportive evidence for the zzso specialization for zzso sounds with realistic zzso We zzso introduce a powerful means to predict brain responses to music, speech, or zzso across a large variety of zzso 

