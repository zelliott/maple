
Many learning rules for neural networks derive from abstract objective zzso The weights in those networks are typically zzso utilizing zzso ascent on the objective zzso In those networks each zzso needs to store two zzso One zzso called activity, contains the bottom-up zzso information involved in the core signal zzso The other variable typically describes the zzso of the objective function with respect to the cell's activity and is exclusively used for zzso This variable allows the objective zzso zzso to be calculated with respect to each weight and thus the weight zzso Although this approach is widely used, the mapping of such two variables onto physiology is zzso and these learning zzso are often considered biologically zzso However, recent research on the properties of cortical zzso zzso shows that these cells have at least two sites of synaptic integration, the zzso and the zzso zzso and are thus appropriately described by at least two zzso Here we discuss whether these results could constitute a zzso basis for the described abstract learning zzso As examples we demonstrate an zzso of the zzso of error zzso and a specific zzso learning zzso using these zzso Thus, compared to standard, zzso zzso it is possible to incorporate interesting properties in neural networks that are inspired by physiology with a modest increase of zzso 

