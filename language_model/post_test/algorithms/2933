
The simulation of zzso neural networks zzso is known to be a very time-consuming zzso This limits the size of zzso that can be simulated in reasonable time or forces users to overly limit the complexity of the zzso zzso This is one of the driving forces behind much of the recent research on zzso simulation zzso Although zzso simulation allows precise and efficient simulation of certain zzso zzso models, it is not straightforward to zzso the technique to more complex zzso models, mostly because the firing time of these zzso models is zzso expensive to zzso Most solutions proposed in literature concentrate on zzso that can solve this problem zzso However, these solutions do not scale well when more state variables are involved in the zzso model, which is, for example, the case when multiple synaptic time zzso for each zzso are zzso In this letter, we show that an exact prediction of the firing time is not required in order to guarantee exact simulation zzso Several techniques are presented that try to do the least possible amount of work to predict the firing zzso We propose an elegant zzso for the simulation of leaky zzso zzso zzso with an arbitrary number of zzso synaptic time constants, which is able to combine these zzso techniques zzso resulting in very high simulation zzso Moreover, our zzso is highly independent of the complexity zzso number of synaptic time zzso of the underlying zzso zzso 

