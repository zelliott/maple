
The zzso of pattern motion in visual area zzso based on motion input from area zzso has been investigated in many experiments and models attempting to replicate the main zzso Two different core conceptual approaches were developed to explain the zzso In zzso models the key mechanism to achieve pattern selectivity is the zzso integration of zzso motion zzso In contrast, zzso models focus on the motion zzso at positions with zzso zzso 

Recent experiments revealed that neither of the two concepts alone is sufficient to explain all experimental data and that most of the existing models cannot account for the complex zzso zzso zzso pattern selectivity changes over time for stimuli like type II zzso from zzso average to the direction zzso with an intersection of constraint rule or by feature zzso Also, the spatial arrangement of the stimulus within the receptive field of a zzso cell plays a crucial zzso We propose a zzso neural model showing how feature integration and selection can be combined into one common architecture to explain these zzso The key features of the model are the zzso of zzso and zzso motion in model area zzso zzso that are integrated in model zzso cells using zzso and feedback zzso Our results are also in line with findings concerning the solution of the zzso zzso 

We propose a new neural model for zzso pattern zzso and motion zzso that is based on a combination of feature selection and zzso The model can explain a range of recent zzso findings including temporally dynamic zzso 

