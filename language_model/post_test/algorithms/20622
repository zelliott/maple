
We present a new zzso for finding zzso neural networks with high zzso zzso The zzso searches for a zzso minimum of the error zzso A flat minimum is a large connected region in weight space where the error remains approximately zzso An zzso zzso argument suggests that flat zzso zzso to zzso networks and low expected zzso The argument is based on a Gibbs zzso zzso and a novel way of splitting zzso error into zzso and zzso zzso Unlike many previous approaches, ours does not require zzso assumptions and does not depend on a zzso weight zzso Instead we have a prior over zzso functions, thus taking into account net architecture and training zzso Although our zzso requires the zzso of zzso zzso it has zzso order of zzso zzso it effectively zzso units, zzso and input zzso Various experiments with zzso and zzso nets are zzso In an application to stock market zzso flat minimum search zzso conventional zzso weight zzso and zzso brain zzso brain zzso 

