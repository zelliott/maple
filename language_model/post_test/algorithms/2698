
Current uses of zzso images typically exploit only the most explicit information: the link between the nouns named and the objects present somewhere in the zzso We propose to leverage zzso cues that rest within an ordered list of image tags so as to improve object zzso We define three novel implicit features from an zzso zzso relative prominence of each object as zzso by its order of mention, the scale constraints implied by unnamed objects, and the loose spatial links hinted at by the proximity of names on the zzso By learning a conditional density over the zzso parameters zzso and zzso given these cues, we show how to improve both accuracy and efficiency when detecting the zzso zzso Furthermore, we show how the zzso density can be learned in a semantic space shared by the visual and zzso features, which makes the technique zzso for detection in zzso input zzso We validate our approach on the zzso zzso zzso and Flickr image data sets, and demonstrate its effectiveness relative to both traditional sliding windows as well as a visual context zzso Our zzso improves state-of-the-art methods, successfully translating insights about human viewing behavior (such as attention, perceived importance, or zzso into enhanced object zzso 

