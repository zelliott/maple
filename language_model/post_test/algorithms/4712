
In this paper, we propose a novel framework called zzso light field zzso which allows continuous exploration of a dynamic scene in both space and zzso Compared to existing light field zzso systems, it offers the capability of using zzso video zzso and the added freedom of controlling the zzso in the zzso domain, such as smooth slow motion and zzso zzso In order to zzso novel views from any viewpoint at any time instant, we develop a zzso rendering zzso We first zzso in the zzso domain to generate globally synchronized images using a robust zzso image registration zzso followed by zzso image zzso We then zzso these zzso images in the spatial domain to zzso the final zzso In addition, we introduce a very accurate and robust zzso to estimate zzso zzso zzso among input video zzso Experimental results from zzso videos with or without time stamps show that our approach is capable of maintaining zzso quality from a variety of real zzso 

