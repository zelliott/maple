
Human beings seem to be able to recognize emotions from speech very well and information communication technology aims to implement machines and agents that can do the zzso However, to be able to automatically recognize affective states from speech signals, it is necessary to solve two main technological zzso The former concerns the identification of effective and efficient processing zzso capable of capturing emotional acoustic features from speech zzso The latter focuses on finding zzso models able to zzso with an approximation as good as human zzso a given set of emotional zzso This paper will survey these topics and provide some insights for a holistic approach to the automatic analysis, recognition and synthesis of affective zzso 

