
A new field of research is rapidly expanding at the zzso between statistical physics, information theory and zzso zzso In particular, the use of cutting edge statistical physics concepts and methods allow one to solve very large constraint satisfaction problems like random zzso zzso or error zzso Several aspects of these developments should be relevant for the understanding of functional complexity in neural zzso On the one hand the message passing procedures which are used in these new zzso are based on local exchange of information, and succeed in solving some of the hardest zzso zzso On the other hand some crucial zzso problems in zzso like those generated in zzso recordings, naturally translate into hard constraint satisfaction zzso This paper gives a zzso introduction to this field, emphasizing the main ideas at work in message passing strategies and their possible relevance to neural networks zzso It also introduces a new message passing zzso for zzso interactions between variables from correlation data, which could be useful in the analysis of zzso recording zzso 

