
This paper investigates new learning zzso zzso I and zzso zzso based on zzso function for the training of zzso neural zzso It is observed that such zzso have interesting parallel with the popular zzso zzso zzso where the fixed learning rate is replaced by an zzso learning rate zzso using convergence zzso based on zzso stability zzso zzso II, a modified version of zzso I, has been introduced with an aim to avoid local zzso This modification also helps in improving the convergence speed in some zzso zzso for achieving global minimum for these kind of zzso have been studied in zzso The performances of the proposed zzso are compared with zzso zzso and extended Kalman filtering zzso on three zzso function approximation problems: zzso zzso parity, and zzso zzso The comparisons are made in terms of number of learning zzso and zzso time required for zzso It is found that the proposed zzso zzso I and zzso are much faster in convergence than other two zzso to attain same zzso Finally, the comparison is made on a complex two-dimensional zzso zzso function and effect of zzso learning rate for faster convergence is zzso In a zzso the investigations made in this paper help us better understand the learning procedure of zzso neural networks in terms of zzso learning rate, convergence speed, and local zzso 

