
This paper shows how to formally characterize language learning in a finite zzso space, for instance, in the zzso approach to language, as a zzso zzso New language learning results follow zzso we can explicitly calculate how many positive examples on average zzso zzso it will take for a zzso to correctly identify a target language with high zzso We show how sample complexity varies with input zzso and learning zzso In particular we find that the average time to zzso under reasonable language input zzso for a simple zzso system first described by Gibson and Wexler zzso is psychologically zzso in the range of zzso positive zzso We further find that a simple random step zzso is, simply jumping from one language hypothesis to another rather than changing one zzso at a zzso faster and always zzso to the right target language, in contrast to the zzso local zzso setting method advocated in some recent zzso 

