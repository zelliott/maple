
In our previous research, we proposed a method for the reproduction of complex movement zzso and robot arm control that could mimic fast, skilled human zzso That method is based on zzso theory and uses a representation of a set of zzso as boundary conditions or control variables to perform robot arm trajectory zzso The zzso are extracted from human movement data and the zzso zzso representation is able to zzso handwritten characters, control a zzso toy, and perform a tennis zzso The zzso information contains both spatial and zzso information, that is, the position on the trajectory and the time of passing through the zzso position, zzso zzso generation is performed using the trajectory formation model based on the optimal zzso zzso the zzso zzso for which the boundary conditions are both the position and the timing of the zzso zzso However, generating a smooth trajectory at different movement speeds is quite difficult if the time of passing through the zzso position is unknown or different from the extracted zzso zzso In this paper, we therefore propose a new zzso which can determine zzso zzso zzso Our proposed zzso can generate roughly the same trajectory as the measured human trajectory from only the spatial information of zzso zzso The zzso and the convergence of the new zzso are investigated zzso and the trajectory generated by the zzso is shown in zzso zzso It is shown that starting from arbitrary zzso information the proposed zzso can produce an appropriate zzso 

