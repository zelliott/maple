
Image representation plays an important role in medical image zzso The key to the success of different medical image analysis zzso is heavily dependent on how we represent the input data, namely features used to characterize the input zzso In the literature, feature engineering remains as an active research topic, and many novel zzso features are designed such as zzso zzso zzso of oriented zzso and local zzso zzso However, such features are not designed with the guidance of the underlying zzso at zzso To this end, we argue that the most effective features should be designed in a learning based manner, namely representation learning, which can be adapted to different patient zzso at zzso In this paper, we introduce a deep learning framework to achieve this zzso Specifically, a stacked independent zzso analysis zzso network is adopted to learn the most effective features in a zzso and zzso zzso The zzso features are adapted to the zzso at hand and zzso high level semantic anatomical zzso The proposed method is evaluated on the application of automatic prostate MR zzso Experimental results show that significant zzso accuracy improvement can be achieved by the proposed deep learning method compared to other state-of-the-art zzso zzso 

