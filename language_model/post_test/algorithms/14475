
This paper introduces a novel contextual model for the recognition of people's visual focus of attention zzso in meetings from zzso zzso zzso More specifically, instead of independently recognizing the zzso of each meeting participant from his own head pose, we propose to jointly recognize the zzso visual attention in order to introduce zzso interaction models that relate to group activity and the social dynamics of zzso Meeting contextual information is represented by the location of people, conversational events identifying floor holding patterns, and a presentation activity zzso By modeling the interactions between the different contexts and their combined and sometimes contradictory impact on the gazing behavior, our model allows us to handle zzso recognition in difficult zzso meetings involving artifacts, presentations, and moving zzso We validated our model through rigorous evaluation on a publicly available and challenging data set of 12 real meetings (5 hours of zzso The results demonstrated that the integration of the presentation and conversation zzso context using our model can lead to significant performance zzso 

