
In this paper, we present a novel approach of implementing a combination methodology to find appropriate neural network architecture and weights using an evolutionary least square based zzso zzso This paper focuses on aspects such as the zzso of updating weights using an evolutionary least square based algorithm, finding the number of hidden zzso for a two layer feed forward neural network, the stopping criterion for the zzso and finally some comparisons of the results with other existing methods for searching optimal or near optimal solution in the zzso complex search space zzso the architecture and the weight zzso We explain how the weight updating zzso using evolutionary least square based approach can be combined with the growing architecture model to find the optimum number of hidden zzso We also discuss the issues of finding a zzso solution space as a starting point for the least square method and address the problems involving fitness zzso We apply the proposed approach to zzso problem, 10 bit odd parity problem and many real-world benchmark data sets such as handwriting data set from zzso breast cancer and heart disease data sets from zzso zzso zzso The comparative results based on zzso accuracy and the time complexity are zzso 

