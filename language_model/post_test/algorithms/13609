
An echo state network zzso consists of a large, randomly connected neural network, the zzso which is driven by an input signal and projects to output zzso During training, only the connections from the zzso to these output units are zzso A key requisite for zzso training is the echo state property zzso which means that the effect of initial conditions should zzso as time zzso In this paper, we use zzso examples to show that a widely used criterion for the zzso the spectral radius of the weight zzso being smaller than unity, is not sufficient to satisfy the echo state zzso We obtain these examples by investigating local zzso properties of the standard zzso Moreover, we provide new sufficient conditions for the echo state property of standard zzso and leaky zzso zzso We zzso suggest an improved technical definition of the echo state property, and discuss what zzso should (and should zzso observe when they zzso their reservoirs for specific zzso 

