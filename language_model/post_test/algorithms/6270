
This paper presents two novel approaches, zzso zzso with magnified zzso function zzso and deterministic weight modification zzso to speed up the convergence rate and improve the global convergence capability of the standard zzso learning zzso The purpose of zzso is to increase the convergence rate by magnifying the zzso function of the zzso function, while the main objective of zzso is to reduce the system error by changing the weights of a multilayered zzso neural network in a deterministic zzso zzso results show that the performance of the above two approaches is better than zzso and other modified zzso zzso for a number of learning zzso Moreover, the integration of the above two approaches forming a new zzso called zzso can further improve the performance of zzso and zzso From our simulation results, the zzso zzso always zzso zzso and other modified zzso zzso in terms of convergence rate and global convergence zzso 

